# C++ 高级线程池项目实验报告

---

## 1. 程序（项目）背景

### 1.1 功能概述

本项目围绕一个自定义的 `ThreadPool` 类展开，可以把它理解为“一个可以重复使用的线程工人团队”。程序启动时，线程池会预先创建若干个工作线程，这些线程不会像普通示例那样用完就销毁，而是长期“待命”。当主程序通过接口提交任务时，这些任务会被放入一个内部的任务队列中，空闲的工作线程会自动从队列中取出任务并执行，从而实现多核 CPU 的并行利用。

在线程池的最基础层面，项目首先实现了**任务的统一提交接口**。无论是简单的 `void()` 任务，还是带参数、带返回值的复杂计算，都可以通过同一个 `enqueue` 函数提交。这个接口接受任意可调用对象（例如 lambda 表达式、普通函数、函数对象等），同时支持附带多个参数，因此在使用体验上更像是“把一段普通函数调用交给线程池去异步执行”。

在此基础上，线程池进一步支持**带返回值的异步任务**。内部通过 `std::packaged_task` 与 `std::future` 这对标准库组件，对用户提交的函数进行包装。用户在提交任务时会得到一个 `std::future` 对象，后续只需在需要结果时调用 `future.get()`，就可以像使用普通函数返回值一样，获得异步计算的结果；如果任务内部抛出了异常，这个异常也会在 `get()` 时被重新抛出并被捕获，保证了错误不会悄悄“吞掉”。

为了让线程池在实际工程中更加可控，本项目还提供了**等待所有任务完成**的能力。`wait_all()` 成员函数会一直阻塞调用方，直到当前队列中所有任务都被执行完毕。与简单粗暴的 `sleep_for` 不同，它通过原子计数器和条件变量精确判断“还有没有未完成的任务”，既保证了结果的正确性，又避免了不必要的时间浪费。

在线程管理方面，线程池提供了**暂停 / 恢复以及动态调整线程数量**等高级控制功能。调用 `pause()` 后，工作线程会在安全的位置停在等待状态，不再从队列中取任务；`resume()` 则会恢复它们继续工作。`reset(size_t new_thread_count)` 则在等待当前任务全部完成之后，安全地销毁旧线程并重新创建指定数量的新线程，使得线程池可以根据运行阶段的需求灵活调整并发度。

除此之外，线程池还内置了一组**监控接口**，用来从外部观察线程池的运行状态。例如，`get_thread_count()` 可以查询当前有多少个工作线程，`get_tasks_queued()` 可以看到任务队列中尚未开始执行的任务数量，`get_tasks_total()` 与 `get_tasks_completed()` 分别反映了未完成和已完成任务的总数。通过一个 `thread_local` 变量，`get_worker_index()` 还可以让每个工作线程在输出日志时报告自己的“线程编号”，便于调试和演示。

在更高一层的抽象上，线程池对外提供了几个**并行算法风格的接口**。`parallel_for` 可以把一个普通的 `for` 循环拆分为多个小块，平均分配给不同的线程去执行；`parallel_reduce` 则在此基础上增加了“局部计算 + 结果归约”的逻辑，可以用来实现并行求和、并行求积等统计运算。这些接口让使用者可以只关注“要做什么运算”，而不必手动管理线程和任务划分。

为了验证以上功能是否正确、稳定，本项目在 `main.cpp` 中设计了 10 组测试用例，分别覆盖了基础任务提交、带返回值任务、带参数任务、并行 for、并行 reduce、暂停/恢复、动态重设线程数、状态监控接口、串行与并行性能对比以及异常处理等多个方面。通过一次运行即可在终端中看到完整的测试过程和结果，便于老师从整体上把握该线程池的设计与实现情况。

### 1.2 背景与意义

随着 CPU 多核化发展，**并发与并行编程**已经成为现代软件开发中的重要能力。线程池作为一种典型的**"线程复用 + 任务队列"**模型，能够显著减少线程频繁创建和销毁带来的开销，提高系统吞吐量。

本项目参考了 Barak Shoshany 提供的 **BS::thread_pool** 开源库的设计思想，在此基础上：
- 自己从零开始实现了一个简化但功能完整的线程池
- 理解并运用了 C++17 标准库中的多线程相关组件
- 做了适度扩展（如 pause/resume、parallel_reduce、监控接口等）

通过本项目，我不仅巩固了《C++程序设计》课程中关于类与模板的知识，而且对**同步原语、任务调度、并行算法**有了更深刻的实践理解。

---

## 2. 相关技术

### 2.1 使用的 C++ 语言知识

在语言层面，本项目几乎把《C++ 程序设计》课程中涉及到的核心语法点都串联了起来。首先，在**类与对象**方面，通过设计 `ThreadPool` 这样一个相对完整的类，我重新回顾了构造函数、析构函数、成员函数、访问控制等基础内容。例如，线程池提供了一个默认构造函数，会根据 `std::thread::hardware_concurrency()` 自动选择合适的线程数量；同时又提供了一个可以指定线程数的构造函数，方便在测试中控制并发度。在析构函数中，类负责发出停止信号并 `join` 所有工作线程，体现了典型的 RAII 管理资源思想。

其次，在**拷贝控制**方面，我显式地将拷贝构造函数和拷贝赋值运算符声明为 `= delete`，禁止线程池对象被随意拷贝。这是因为线程池内部管理着线程、互斥锁等底层资源，如果允许默认拷贝，很容易出现多个对象同时持有同一批线程句柄的危险情况。通过禁用拷贝，可以强制用户以引用或指针的方式传递线程池对象，保证资源管理的唯一性。

在**模板与泛型编程**方面，最重要的是可变参数模板 `template<class F, class... Args>` 的使用。借助这一语法，`enqueue` 不再局限于接受某一种固定形式的函数指针，而是可以接收任意可调用对象以及任意数量和类型的参数。再配合 `std::invoke_result_t<F, Args...>` 这种类型萃取工具，线程池可以自动推断出任务的返回类型，从而返回对应的 `std::future<Ret>`，使得接口既简洁又类型安全。

此外，项目中大量使用了 STL 容器和算法。例如，使用 `std::vector<std::thread>` 存放所有工作线程，使用 `std::queue<std::function<void()>>` 作为任务队列，利用 `std::min` 计算并行块的边界等。这些容器和算法的使用，使得整体实现更加偏向“以库为中心”的现代 C++ 风格，而不是手写裸指针和数组。

在**异常处理**方面，线程池在两个层次上考虑了安全性：一方面，如果用户在已经停止的线程池上继续调用 `enqueue`，内部会抛出 `std::runtime_error`，提醒错误使用；另一方面，对于带返回值的任务，异常会被 `packaged_task` 捕获并通过 `future` 传播到调用方，这样不会导致整个工作线程崩溃，而是由主线程在 `get()` 时统一处理。

最后，在 `const` 使用上也有一些细节。例如，一些查询接口被声明为 `const` 成员函数，但内部仍然需要对互斥锁加锁。为了解决这一冲突，我将 `queue_mutex` 声明为 `mutable`，从而在逻辑上保持“查询函数不修改抽象状态”，同时又能在实现细节上保证线程安全。这些小地方的处理，让我对 C++ 类型系统与实际工程需求之间的平衡有了更直观的体验。

### 2.2 关键技术介绍

从实现角度看，本项目主要依赖四类关键技术：多线程原语、模板与泛型、标准库并发组件以及线程本地存储。

首先是**多线程技术**。`std::thread` 提供了最基本的线程创建能力，线程池中的每一个工作线程本质上就是一个运行着 `worker_loop` 函数的 `std::thread` 对象。为了避免多个线程同时访问任务队列而产生数据竞争，我使用了 `std::mutex` 配合 `std::lock_guard`/`std::unique_lock` 进行互斥保护；当任务队列为空时，工作线程不会忙等，而是通过 `std::condition_variable` 进入休眠，直到有新的任务被提交并调用 `notify_one()` 或 `notify_all()` 唤醒，这样既保证了正确性，又避免了 CPU 资源的浪费。

第二类是**模板与泛型技术**。线程池的 `enqueue`、`parallel_for`、`parallel_reduce` 等接口都设计成模板函数，用来适配不同的任务类型和数据范围。以 `parallel_for` 为例，它接受一个区间 `[first, last)` 和一个函数对象 `f`，内部会根据当前线程数自动把区间切分成若干个小块，并为每个小块提交一个任务。这样一来，用户在调用时只需要写出普通的循环体逻辑即可，不需要关心具体的并行划分细节。

第三类是**STL 和并发组件**。任务队列使用 `std::queue<std::function<void()>>` 实现，这样无论原始任务是带参数还是有返回值，最终都可以被封装成统一的 `void()` 形式存入队列；`std::atomic<size_t>` 则用于统计未完成任务数和已完成任务数，它们在多线程环境下可以无锁地进行自增自减操作，避免了额外的互斥开销。`std::future` 与 `std::packaged_task` 的组合，则让“提交任务”和“获取结果”解耦：提交时只负责描述要做什么，获取结果的时机则完全由调用者自己决定。

最后是**线程本地存储技术**。通过在类中声明 `static thread_local size_t worker_index;`，每个工作线程都会拥有一份独立的 `worker_index` 变量。在启动线程时，我会把线程在数组中的下标写入这个变量，这样在任务执行函数中调用 `ThreadPool::get_worker_index()` 时，就能知道当前代码是由哪一个工作线程执行的。这个机制一方面方便了调试和输出日志，另一方面也体现了 `thread_local` 在实际项目中的一个典型用法。

### 2.3 使用的 C++ 标准库类

综合来看，本项目大量依赖 C++17 标准库，而没有引入任何第三方依赖。所有并发相关功能都由 `<thread>`、`<mutex>`、`<condition_variable>`、`<future>`、`<atomic>` 等头文件提供；而数据结构和工具函数则主要来自 `<vector>`、`<queue>`、`<functional>` 等常用头文件。通过这些类库的组合，我体会到现代 C++ 已经为多线程编程提供了相对完备的基础设施，开发者更多需要思考的是“如何合理组织这些组件”，而不是从零开始造轮子。
---

## 3. 程序（项目）设计

### 3.1 开发思路

整个项目分为两层：

**（1）线程池库层（Library）**
- 由 `ThreadPool` 类组成
- 负责管理工作线程、任务队列和各种并发控制逻辑
- 提供对外接口：`enqueue`、`wait_all`、`parallel_for`、`parallel_reduce`、`pause`、`reset` 等

**（2）演示与测试层（Application）**
- 由 `main.cpp` 构成
- 通过 10 组测试，验证并展示线程池的各项功能

### 3.2 项目架构图

```
┌─────────────────────────────────────────────────────────────┐
│                      main.cpp (测试程序)                      │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ │
│  │ Test 1  │ │ Test 2  │ │ Test 3  │ │  ...    │ │ Test 10 │ │
│  └────┬────┘ └────┬────┘ └────┬────┘ └────┬────┘ └────┬────┘ │
└───────┼──────────┼──────────┼──────────┼──────────┼─────────┘
        │          │          │          │          │
        ▼          ▼          ▼          ▼          ▼
┌─────────────────────────────────────────────────────────────┐
│                    ThreadPool 类 (线程池库)                   │
│  ┌──────────────────────────────────────────────────────┐   │
│  │                    公有接口                            │   │
│  │  enqueue() | wait_all() | parallel_for() | pause()   │   │
│  │  resume()  | reset()    | get_thread_count() | ...   │   │
│  └──────────────────────────────────────────────────────┘   │
│  ┌──────────────────────────────────────────────────────┐   │
│  │                    私有成员                            │   │
│  │  workers (线程数组) | tasks (任务队列)                  │   │
│  │  queue_mutex | condition | stop | paused              │   │
│  │  tasks_total | tasks_completed                        │   │
│  └──────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘
```

### 3.3 核心流程说明

在线程池的运行过程中，可以把整个行为分成“主线程提交任务”和“工作线程取任务执行”两大部分。下面用文字的形式，把这一过程串联起来，方便没有多线程基础的读者理解。

当用户在主程序中调用 `enqueue(f, args...)` 时，首先发生的事情并不是“立刻新开一个线程去执行 f”，而是由线程池把这次函数调用包装成一个可以稍后执行的“任务对象”。具体来说，线程池会使用 `std::packaged_task` 把函数 `f` 以及它的参数 `args...` 封装起来，同时生成一个与之对应的 `std::future` 对象。这个 future 就像是一张“取货凭证”，以后可以用它来领取任务的返回值。

任务被打包好之后，并不会马上执行，而是被放入线程池内部维护的任务队列 `tasks` 中。为了避免多个线程同时修改队列发生冲突，在线程池向队列中压入新任务时，会先获得互斥锁 `queue_mutex`，再将任务放入队列，最后调用 `condition.notify_one()` 唤醒正在等待任务的工作线程。与此同时，表示“尚未完成任务数量”的计数器 `tasks_total` 也会加一，为后续的 `wait_all()` 提供精确的统计信息。主线程在完成这些步骤后，就可以立即返回，并通过之前得到的 future 在今后合适的时机获取结果，而不必原地等待任务执行完毕。

另一方面，线程池在创建时会启动若干个工作线程，每个线程都在 `worker_loop()` 函数中循环运行。它们的大致行为是：先获取队列锁，然后在条件变量 `condition` 上进入等待状态。只有当满足“收到停止信号”或者“当前不是暂停状态并且任务队列非空”这两个条件之一时，线程才会被唤醒继续执行。如果此时发现线程池已经处于停止状态并且任务队列为空，说明不再有新任务需要处理，该工作线程就会安全地退出循环并结束生命周期；否则，它就从队列头部取出一个任务对象，把队列中的这一项弹出，然后在解锁互斥锁之后执行该任务。

每当一个任务执行完成，工作线程都会把 `tasks_completed` 计数器加一，与此同时，对应的 `tasks_total` 计数器会在任务包装函数内部递减。当 `tasks_total` 递减到 0 且任务队列为空时，线程池会通过 `tasks_done_cv.notify_all()` 唤醒在 `wait_all()` 中等待的主线程。这样一来，主线程既可以选择“火车一到就取货”（立即等待所有任务完成），也可以选择“过一会儿再来取”（通过 future 在稍后时刻获取单个任务的结果），二者互不冲突，又都建立在同一套计数与同步机制之上。
### 3.4 数据结构

| 数据结构 | 类型 | 说明 |
|----------|------|------|
| 工作线程数组 | `std::vector<std::thread>` | 存储所有工作线程 |
| 任务队列 | `std::queue<std::function<void()>>` | FIFO 队列存储待执行任务 |
| 任务计数器 | `std::atomic<size_t>` | 无锁计数，跟踪未完成任务数 |

### 3.5 ThreadPool 类图

```
┌─────────────────────────────────────────────────────────┐
│                       ThreadPool                         │
├─────────────────────────────────────────────────────────┤
│ - workers: vector<thread>          // 工作线程数组       │
│ - tasks: queue<function<void()>>   // 任务队列          │
│ - queue_mutex: mutex               // 队列互斥锁        │
│ - condition: condition_variable    // 条件变量          │
│ - stop: bool                       // 停止标志          │
│ - paused: bool                     // 暂停标志          │
│ - tasks_total: atomic<size_t>      // 未完成任务数      │
│ - tasks_completed: atomic<size_t>  // 已完成任务数      │
│ - worker_index: thread_local size_t // 线程编号         │
├─────────────────────────────────────────────────────────┤
│ + ThreadPool()                                          │
│ + ThreadPool(num_threads: size_t)                       │
│ + ~ThreadPool()                                         │
│ + enqueue<F, Args...>(f, args) : future<R>              │
│ + wait_all() : void                                     │
│ + pause() : void                                        │
│ + resume() : void                                       │
│ + reset(new_count: size_t) : void                       │
│ + parallel_for<Func>(first, last, f) : void             │
│ + parallel_reduce<T, Func>(first, last, init, f) : T    │
│ + get_thread_count() : size_t                           │
│ + get_tasks_queued() : size_t                           │
│ + get_worker_index() : size_t  [static]                 │
├─────────────────────────────────────────────────────────┤
│ - worker_loop() : void             // 工作线程主循环     │
│ - start_workers(num: size_t) : void // 启动工作线程      │
└─────────────────────────────────────────────────────────┘
```

---

## 4. 程序（项目）实现

### 4.1 关键代码与实现思路

在线程池的全部实现中，有两段代码最能体现其工作原理：一段是负责**接收并封装任务**的 `enqueue`，另一段是每个工作线程不断循环执行任务的 `worker_loop`。下面我选取这两段代码，并在代码内部穿插简短注释，帮助没有多线程经验的读者也能顺着代码把握思路。

**（1）模板版任务提交 `enqueue`（支持返回值和任意参数）**

```cpp
// 接收任意可调用对象 F 以及任意数量的参数 Args，
// 自动推导出返回类型，并返回一个 future 以便异步获取结果。
template<class F, class... Args>
auto ThreadPool::enqueue(F&& f, Args&&... args)
    -> std::future<std::invoke_result_t<F, Args...>>
{
    using return_type = std::invoke_result_t<F, Args...>; // 推导 f(args...) 的返回类型

    // 1. 用 packaged_task 把「函数 + 参数」包装成一个可调用任务对象，
    //    以后只需要调用 (*task)() 就能自动完成参数绑定和执行。
    auto task = std::make_shared<std::packaged_task<return_type()>>(
        std::bind(std::forward<F>(f), std::forward<Args>(args)...)
    );

    // 2. 从 packaged_task 中拿到 future，供调用者以后获取返回值。
    std::future<return_type> result = task->get_future();

    {
        // 3. 加锁保护任务队列，防止多个线程同时修改队列。
        std::unique_lock<std::mutex> lock(queue_mutex);
        if (stop) {
            // 如果线程池已经停止，禁止继续提交任务，避免逻辑混乱。
            throw std::runtime_error("enqueue on stopped ThreadPool");
        }

        // 记录还有多少任务尚未完成，便于 wait_all() 精确等待。
        ++tasks_total;

        // 4. 把真正要执行的内容压入任务队列：
        //    这里只保存一个无参数的 lambda，内部再去调用 packaged_task。
        tasks.emplace([this, task]() {
            (*task)();              // 执行用户提交的任务（可能有返回值/异常）
            if (--tasks_total == 0) {
                // 当最后一个任务完成时，唤醒在 wait_all() 中等待的线程。
                std::unique_lock<std::mutex> done_lock(tasks_done_mutex);
                tasks_done_cv.notify_all();
            }
        });
    }

    // 5. 通知一个正在休眠的工作线程：有新任务可以处理了。
    condition.notify_one();
    return result;  // 把 future 交还给调用者
}
```

这段代码体现了线程池接口设计的几个特点：外部看起来只有一个简单的 `enqueue`，但内部既完成了任务的类型擦除（统一转换成 `std::function<void()>` 形式），又处理好了任务计数、异常传播以及与 `wait_all()` 的配合，真正做到了“对外简单、对内完整”。

**（2）工作线程主循环 `worker_loop`**

```cpp
// 每个工作线程启动后都会在 worker_loop 中「循环一辈子」，
// 直到收到停止信号并且队列中不再有任务需要处理。
void ThreadPool::worker_loop() {
    while (true) {
        std::function<void()> task;   // 用于接收即将被执行的任务
        {
            std::unique_lock<std::mutex> lock(queue_mutex);

            // 1. 在条件变量上等待：
            //    只有当(收到停止信号) 或者(当前未暂停且队列非空) 时才会被唤醒。
            condition.wait(lock, [this]() {
                return stop || (!paused && !tasks.empty());
            });

            // 2. 如果已经要求停止，并且队列里也没有任务了，
            //    说明线程池生命周期结束，当前工作线程可以安全退出。
            if (stop && tasks.empty()) {
                return;
            }

            // 3. 如果此时处于「暂停」状态，但还没有 stop，
            //    说明只是临时按下了暂停键，当前循环直接继续等待即可。
            if (paused && !stop) {
                continue;
            }

            // 4. 从队列头部取出一个任务，并把它移出队列。
            task = std::move(tasks.front());
            tasks.pop();
        } // 解锁 queue_mutex，后续执行任务不再占用队列锁。

        // 5. 在锁外执行任务，避免长时间占用互斥量，
        //    否则会影响其他线程提交或获取任务。
        task();

        // 6. 记录已完成任务数量，便于监控接口统计。
        ++tasks_completed;
    }
}
```

这段循环逻辑展示了一个典型的生产者–消费者模型：主线程持续向队列中投递“产品”（任务），而一组工作线程则在条件变量的配合下高效地消费这些任务。通过在取任务前后精细地控制加锁和解锁的范围，既保证了数据结构的安全，又避免了长时间持锁造成的性能瓶颈。
### 4.2 遇到的问题和解决方案

| 问题 | 原因 | 解决方案 |
|------|------|----------|
| 编译错误：`const` 函数中无法加锁 | `std::mutex::lock()` 是非 const 操作 | 将 `queue_mutex` 声明为 `mutable` |
| 控制台输出混乱 | 多线程同时写 `cout` 导致交错 | 使用全局 `cout_mutex` 保护输出 |
| exe 文件无法运行（16位兼容错误） | 编译时使用了错误的参数 | 使用 `-m64` 参数显式编译为 64 位 |
| `wait_all()` 无法正确等待 | 计数器与条件变量配合不当 | 任务完成时检查计数器，为 0 时 `notify_all()` |
| 程序运行完窗口立即关闭 | 控制台程序执行完即退出 | 在 `main()` 末尾添加 `std::cin.get()` |

---

## 5. 结果展示与分析

### 5.1 运行界面

程序运行后输出如下（部分截取）：

```
  ╔═══════════════════════════════════════════════════════╗
  ║     ADVANCED THREAD POOL - COMPREHENSIVE TEST SUITE   ║
  ╚═══════════════════════════════════════════════════════╝

============================================================
  Test 1: Basic Task Submission
============================================================
Thread pool created with 4 threads

  Task 0 executed by worker #0
  Task 1 executed by worker #1
  Task 2 executed by worker #2
  Task 3 executed by worker #3
  Task 4 executed by worker #0
  Task 5 executed by worker #1
  Task 6 executed by worker #2
  Task 7 executed by worker #3

All tasks completed. Total executed: 8

============================================================
  Test 5: Parallel Reduce
============================================================
Sum of 1 to 100 = 5050
Expected: 5050 -> PASS
10! = 3628800 (expected: 3628800) -> PASS

============================================================
  Test 9: Performance Benchmark
============================================================
Serial computation: 39 ms
Using 20 threads
Parallel computation: 5 ms
Speedup: 7.80x

============================================================
  ALL TESTS COMPLETED SUCCESSFULLY
============================================================

Thread Pool Features Demonstrated:
  [x] Basic task submission
  [x] Tasks with return values (std::future)
  [x] Tasks with parameters
  [x] Parallel for loop
  [x] Parallel reduce
  [x] Pause and resume
  [x] Dynamic thread count reset
  [x] Monitoring interface
  [x] Performance benchmark
  [x] Exception handling
```

### 5.2 测试结果分析

| 测试项 | 验证内容 | 结果 |
|--------|----------|------|
| Test 1 | 基础任务提交，8 个任务分配给 4 个线程 | ✅ 通过 |
| Test 2 | 带返回值任务，计算 0²~9² | ✅ 结果正确 |
| Test 3 | 带参数任务，传递参数并获取结果 | ✅ 通过 |
| Test 4 | parallel_for 并行循环 | ✅ 16 个平方值正确 |
| Test 5 | parallel_reduce 求和与阶乘 | ✅ 5050 和 3628800 正确 |
| Test 6 | 暂停/恢复功能 | ✅ 暂停期间任务不增加 |
| Test 7 | 动态重设线程数 | ✅ 2→4 线程切换成功 |
| Test 8 | 监控接口 | ✅ 计数器工作正常 |
| Test 9 | 性能基准 | ✅ 加速比约 7.8x |
| Test 10 | 异常处理 | ✅ 异常被正确捕获 |

**性能分析：**
- 串行执行 100 万次三角函数计算耗时约 39ms
- 使用 20 线程并行执行耗时约 5ms
- 加速比约 7.8 倍（受限于 CPU 核心数和调度开销）

---

## 6. 心得体会

通过本次线程池项目的开发，我收获了以下几点：

**（1）深入理解了多线程编程**
- 掌握了 `std::thread`、`std::mutex`、`std::condition_variable` 的使用
- 理解了生产者-消费者模型在线程池中的应用
- 学会了如何避免数据竞争和死锁

**（2）提升了 C++ 模板编程能力**
- 使用可变参数模板实现泛型任务提交
- 理解了 `std::invoke_result_t` 等类型推导工具
- 掌握了完美转发的应用场景

**（3）体会到了工程实践的重要性**
- 代码需要考虑边界情况（如线程数为 0、空队列等）
- 多线程输出需要加锁保护
- 程序需要考虑用户的使用体验（如按任意键退出）

**（4）学会了参考开源项目进行学习**
- 通过阅读 BS::thread_pool 的设计思想，了解了工业级线程池的实现方式
- 在参考的基础上进行简化和创新，形成自己的理解

总的来说，这个项目让我从"会用多线程"提升到了"能设计多线程框架"的层次，为今后的并发编程打下了坚实基础。

---

## 7. 参考文献

[1] Barak Shoshany. BS::thread_pool - A fast, lightweight, and easy-to-use C++17 thread pool library [EB/OL]. https://github.com/bshoshany/thread-pool, 2024.

[2] cppreference.com. C++ Reference - Thread support library [EB/OL]. https://en.cppreference.com/w/cpp/thread, 2024.

[3] cppreference.com. std::future [EB/OL]. https://en.cppreference.com/w/cpp/thread/future, 2024.

[4] cppreference.com. std::packaged_task [EB/OL]. https://en.cppreference.com/w/cpp/thread/packaged_task, 2024.

[5] 侯捷. C++ 并发编程实战 (C++ Concurrency in Action) [M]. 人民邮电出版社, 2Mo19.

[6] Stanley B. Lippman. C++ Primer (第5版) [M]. 电子工业出版社, 2013.

---

*报告完成日期：2024年*

